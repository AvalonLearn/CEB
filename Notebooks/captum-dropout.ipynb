{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from cardinality_estimation.featurizer import Featurizer\n",
    "from query_representation.query import load_qrep\n",
    "from cardinality_estimation.dataset import *\n",
    "from torch.utils import data\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-separate",
   "metadata": {},
   "source": [
    "# Setup file paths / Download query data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import errno\n",
    "def make_dir(directory):\n",
    "    try:\n",
    "        os.makedirs(directory)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# TRAINDIR = os.path.join(os.path.join(\"\", \"queries\"), \"mlsys1-train\")\n",
    "# VALDIR = os.path.join(os.path.join(\"\", \"queries\"), \"mlsys1-val\")\n",
    "# TESTDIR = os.path.join(os.path.join(\"\", \"queries\"), \"mlsys1-test\")\n",
    "\n",
    "TRAINDIR = os.path.join(os.path.join(\"\", \"queries\"), \"imdb\")\n",
    "TESTDIR = os.path.join(os.path.join(\"\", \"queries\"), \"imdb\")\n",
    "\n",
    "RESULTDIR = os.path.join(\"\", \"results\")\n",
    "make_dir(RESULTDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-collaboration",
   "metadata": {},
   "source": [
    "# Query loading helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_qdata(fns):\n",
    "    qreps = []\n",
    "    for qfn in fns:\n",
    "        qrep = load_qrep(qfn)\n",
    "        # TODO: can do checks like no queries with zero cardinalities etc.\n",
    "        qreps.append(qrep)\n",
    "        template_name = os.path.basename(os.path.dirname(qfn))\n",
    "        qrep[\"name\"] = os.path.basename(qfn)\n",
    "        qrep[\"template_name\"] = template_name\n",
    "    return qreps\n",
    "\n",
    "def get_query_fns(basedir, template_fraction=1.0, sel_templates=None):\n",
    "    fns = []\n",
    "    tmpnames = list(glob.glob(os.path.join(basedir, \"*\")))\n",
    "    assert template_fraction <= 1.0\n",
    "    \n",
    "    for qi,qdir in enumerate(tmpnames):\n",
    "        if os.path.isfile(qdir):\n",
    "            continue\n",
    "        template_name = os.path.basename(qdir)\n",
    "        if sel_templates is not None and template_name not in sel_templates:\n",
    "            continue\n",
    "        \n",
    "        # let's first select all the qfns we are going to load\n",
    "        qfns = list(glob.glob(os.path.join(qdir, \"*.pkl\")))\n",
    "        qfns.sort()\n",
    "        num_samples = max(int(len(qfns)*template_fraction), 1)\n",
    "        random.seed(1234)\n",
    "        qfns = random.sample(qfns, num_samples)\n",
    "        fns += qfns\n",
    "    return fns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-waterproof",
   "metadata": {},
   "source": [
    "# Evaluation helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(alg, qreps):\n",
    "    if isinstance(qreps[0], str):\n",
    "        # only file paths sent\n",
    "        qreps = load_qdata(qreps)\n",
    "    \n",
    "    ests = alg.test(qreps)\n",
    "    return ests\n",
    "\n",
    "def eval_alg(alg, eval_funcs, qreps, samples_type, result_dir=\"./results/\"):\n",
    "    '''\n",
    "    '''\n",
    "    np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "    alg_name = alg.__str__()\n",
    "    exp_name = alg.get_exp_name()\n",
    "    \n",
    "    if isinstance(qreps[0], str):\n",
    "        # only file paths sent\n",
    "        qreps = load_qdata(qreps)\n",
    "    \n",
    "    ests = alg.test(qreps)\n",
    "\n",
    "    for efunc in eval_funcs:\n",
    "        rdir = None\n",
    "        if result_dir is not None:\n",
    "            rdir = os.path.join(result_dir, exp_name)\n",
    "            make_dir(rdir)\n",
    "\n",
    "        errors = efunc.eval(qreps, ests, samples_type=samples_type,\n",
    "                result_dir=rdir,\n",
    "                num_processes = -1,\n",
    "                alg_name = alg_name,\n",
    "                use_wandb=0)\n",
    "\n",
    "        print(\"{}, {}, #samples: {}, {}: mean: {}, median: {}, 99p: {}\"\\\n",
    "                .format(samples_type, alg, len(errors),\n",
    "                    efunc.__str__(),\n",
    "                    np.round(np.mean(errors),3),\n",
    "                    np.round(np.median(errors),3),\n",
    "                    np.round(np.percentile(errors,99),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-omaha",
   "metadata": {},
   "source": [
    "# Load queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set template_fraction <= 1.0 to test quickly w/ smaller datasets\n",
    "# train_qfns = get_query_fns(TRAINDIR, template_fraction = 0.001)\n",
    "# val_qfns = get_query_fns(VALDIR, template_fraction = 1.0)\n",
    "# test_qfns = get_query_fns(TESTDIR, template_fraction = 1.0)\n",
    "\n",
    "train_qfns = get_query_fns(TRAINDIR, template_fraction = 1.0, sel_templates=[\"2b\"])\n",
    "val_qfns = []\n",
    "test_qfns = get_query_fns(TESTDIR, template_fraction = 1.0, sel_templates=[\"2a\"])\n",
    "\n",
    "print(\"Selected {} training queries, {} validation queries, {} test queries\".\\\n",
    "      format(len(train_qfns), len(val_qfns), len(test_qfns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.eval_fns import QError, SimplePlanCost\n",
    "EVAL_FNS = []\n",
    "EVAL_FNS.append(QError())\n",
    "EVAL_FNS.append(SimplePlanCost())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_featurizer(featurization_type):\n",
    "    # Load database specific data, e.g., information about columns, tables etc.\n",
    "    dbdata_fn = os.path.join(TRAINDIR, \"dbdata.json\")\n",
    "    featurizer = Featurizer(None, None, None, None, None)\n",
    "    with open(dbdata_fn, \"r\") as f:\n",
    "        dbdata = json.load(f)\n",
    "    featurizer.update_using_saved_stats(dbdata)\n",
    "\n",
    "    featurizer.setup(ynormalization=\"log\",\n",
    "        feat_separate_alias = 0,\n",
    "        onehot_dropout = onehot_dropout,\n",
    "        feat_mcvs = 0,\n",
    "        heuristic_features = 1,\n",
    "        featurization_type=featurization_type,\n",
    "        table_features=1,\n",
    "        flow_features = 0,\n",
    "        join_features= \"onehot\",\n",
    "        set_column_feature= \"onehot\",\n",
    "        max_discrete_featurizing_buckets=30,\n",
    "        max_like_featurizing_buckets=10,\n",
    "        embedding_fn = \"none\",\n",
    "        embedding_pooling = None,\n",
    "        implied_pred_features = 0,\n",
    "        feat_onlyseen_preds = 1)\n",
    "    featurizer.update_ystats(trainqs)\n",
    "    \n",
    "    featurizer.update_workload_stats(trainqs)\n",
    "    featurizer.init_feature_mapping()\n",
    "    featurizer.update_ystats(trainqs)\n",
    "\n",
    "    # if feat_onlyseen_preds:\n",
    "    # just do it always\n",
    "    featurizer.update_seen_preds(trainqs)\n",
    "    \n",
    "    return featurizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734edcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to start training the models\n",
    "trainqs = load_qdata(train_qfns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f730aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testqs = load_qdata(test_qfns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a69fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 60\n",
    "lr=0.0001\n",
    "training_opt = \"none\"\n",
    "opt_lr = 0.1\n",
    "swa_start = 5\n",
    "mask_unseen_subplans = 0\n",
    "subplan_level_outputs=0\n",
    "normalize_flow_loss = 1\n",
    "heuristic_unseen_preds = 0\n",
    "cost_model = \"C\"\n",
    "use_wandb = 0\n",
    "eval_fns = \"qerr,plancost\"\n",
    "load_padded_mscn_feats = 1\n",
    "mb_size = 1024\n",
    "weight_decay = 0.0\n",
    "load_query_together = 0\n",
    "result_dir = \"./results\"\n",
    "onehot_dropout=0\n",
    "onehot_mask_truep=0.8\n",
    "onehot_reg=0\n",
    "onehot_reg_decay=0.1\n",
    "eval_epoch = 200\n",
    "optimizer_name=\"adamw\"\n",
    "clip_gradient=20.0\n",
    "loss_func_name = \"mse\"\n",
    "hidden_layer_size = 128\n",
    "num_hidden_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-variable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cardinality_estimation.fcnn import FCNN\n",
    "# featurizer = init_featurizer(\"combined\")\n",
    "# #featurizer = init_featurizer(\"set\")\n",
    "\n",
    "# fcnn = FCNN(max_epochs = max_epochs, lr=lr,\n",
    "#                 training_opt = training_opt,\n",
    "#                 opt_lr = opt_lr,\n",
    "#                 swa_start = swa_start,\n",
    "#                 mask_unseen_subplans = mask_unseen_subplans,\n",
    "#                 subplan_level_outputs=subplan_level_outputs,\n",
    "#                 normalize_flow_loss = normalize_flow_loss,\n",
    "#                 heuristic_unseen_preds = heuristic_unseen_preds,\n",
    "#                 onehot_dropout=onehot_dropout,\n",
    "#                 onehot_reg=onehot_reg,\n",
    "#                 onehot_reg_decay=onehot_reg_decay,\n",
    "#                 cost_model = cost_model,\n",
    "#                 eval_fns = eval_fns,\n",
    "#                 use_wandb = use_wandb,\n",
    "#                 mb_size = mb_size,\n",
    "#                 weight_decay = weight_decay,\n",
    "#                 load_query_together = load_query_together,\n",
    "#                 result_dir = result_dir,\n",
    "#                 num_hidden_layers=num_hidden_layers,\n",
    "#                 eval_epoch = eval_epoch,\n",
    "#                 optimizer_name=optimizer_name,\n",
    "#                 clip_gradient=clip_gradient,\n",
    "#                 loss_func_name = loss_func_name,\n",
    "#                 hidden_layer_size = hidden_layer_size)\n",
    "\n",
    "# fcnn.train(trainqs, valqs=None, testqs=None,\n",
    "#     featurizer=featurizer, result_dir=RESULTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # evaluate model\n",
    "# eval_alg(fcnn, EVAL_FNS, trainqs, \"train\")\n",
    "# # eval_alg(fcnn, EVAL_FNS, valqs, \"val\")\n",
    "\n",
    "# # # TODO: test set prdictions; should submit these for the leaderboard?\n",
    "# # #preds = fcnn.test(testqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cardinality_estimation.mscn import MSCN as MSCN2\n",
    "\n",
    "featurizer = init_featurizer(\"set\")\n",
    "mscn = MSCN2(max_epochs = max_epochs, lr=lr,\n",
    "                training_opt = training_opt,\n",
    "                inp_dropout = 0.0,\n",
    "                hl_dropout = 0.0,\n",
    "                comb_dropout = 0.0,\n",
    "                opt_lr = opt_lr,\n",
    "                swa_start = swa_start,\n",
    "                mask_unseen_subplans = mask_unseen_subplans,\n",
    "                subplan_level_outputs=subplan_level_outputs,\n",
    "                normalize_flow_loss = normalize_flow_loss,\n",
    "                heuristic_unseen_preds = heuristic_unseen_preds,\n",
    "                cost_model = cost_model,\n",
    "                use_wandb = use_wandb,\n",
    "                eval_fns = eval_fns,\n",
    "                load_padded_mscn_feats = load_padded_mscn_feats,\n",
    "                mb_size = mb_size,\n",
    "                weight_decay = weight_decay,\n",
    "                load_query_together = load_query_together,\n",
    "                result_dir = result_dir,\n",
    "                onehot_dropout=onehot_dropout,\n",
    "                onehot_mask_truep=onehot_mask_truep,\n",
    "                onehot_reg=onehot_reg,\n",
    "                onehot_reg_decay=onehot_reg_decay,\n",
    "                # num_hidden_layers=num_hidden_layers,\n",
    "                eval_epoch = eval_epoch,\n",
    "                optimizer_name=optimizer_name,\n",
    "                clip_gradient=clip_gradient,\n",
    "                loss_func_name = loss_func_name,\n",
    "                hidden_layer_size = hidden_layer_size)\n",
    "\n",
    "mscn.train(trainqs, valqs=None, testqs=None,\n",
    "    featurizer=featurizer, result_dir=RESULTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "eval_alg(mscn, EVAL_FNS, trainqs, \"train\")\n",
    "\n",
    "#eval_alg(mscn, EVAL_FNS, valqs, \"val\")\n",
    "# TODO: test set prdictions; should submit these for the leaderboard?\n",
    "#preds = mscn.test(testqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929d80e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_alg(mscn, EVAL_FNS, testqs, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports from captum library\n",
    "from captum.attr import LayerConductance, LayerActivation, LayerIntegratedGradients\n",
    "from captum.attr import IntegratedGradients, DeepLift, GradientShap, NoiseTunnel, FeatureAblation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95f83d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = init_featurizer(\"set\")\n",
    "ds = QueryDataset(trainqs[0:10], featurizer,\n",
    "        True,\n",
    "        load_padded_mscn_feats=True)\n",
    "loader = data.DataLoader(ds,\n",
    "        batch_size=1, shuffle=False,\n",
    "        collate_fn=mscn_collate_fn_together,\n",
    "        )\n",
    "\n",
    "testds = QueryDataset(testqs[0:3], featurizer,\n",
    "        True,\n",
    "        load_padded_mscn_feats=True)\n",
    "testloader = data.DataLoader(testds,\n",
    "        batch_size=1, shuffle=False,\n",
    "        collate_fn=mscn_collate_fn_together,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlparse\n",
    "sql = trainqs[2][\"sql\"]\n",
    "print(sqlparse.format(sql, reindent=True, keyword_case='upper'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9893dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iloader = iter(loader)\n",
    "iloader = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deffab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbatch,y,info = next(iloader)\n",
    "print(torch.sum(xbatch[\"pred\"][:,:,20]))\n",
    "print(torch.sum(xbatch[\"pred\"][:,:,21]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6bc625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4dbcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cardinality_estimation.nets import *\n",
    "mscn_model = mscn.net\n",
    "n_out = 1\n",
    "sfeats = mscn_model.sample_mlp1.in_features\n",
    "pfeats = mscn_model.predicate_mlp1.in_features\n",
    "jfeats = mscn_model.join_mlp1.in_features\n",
    "\n",
    "net = SetConvNoFlow(sfeats,\n",
    "    pfeats, jfeats,\n",
    "    128,\n",
    "    n_out=n_out,\n",
    "    dropouts=[0.0, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e537083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)\n",
    "print(mscn_model)\n",
    "net.load_state_dict(mscn_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976f292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(xbatch[\"pred\"][:,:,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca888b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net\n",
    "model.eval()\n",
    "ig = IntegratedGradients(model)\n",
    "ig_nt = NoiseTunnel(ig)\n",
    "dl = DeepLift(model)\n",
    "gs = GradientShap(model)\n",
    "fa = FeatureAblation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0767309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xbatch = ds.X[32]\n",
    "# ig_attr_test = ig.attribute(tuple([xbatch[\"table\"].unsqueeze(0), xbatch[\"pred\"].unsqueeze(0),\n",
    "#                             xbatch[\"join\"].unsqueeze(0), xbatch[\"flow\"].unsqueeze(0),\n",
    "#                             xbatch[\"tmask\"].unsqueeze(0), xbatch[\"pmask\"].unsqueeze(0), \n",
    "#                                    xbatch[\"jmask\"].unsqueeze(0)]), n_steps=50)\n",
    "ig_attr_test = ig.attribute(tuple([xbatch[\"table\"], xbatch[\"pred\"],\n",
    "                            xbatch[\"join\"], \n",
    "                            xbatch[\"tmask\"], xbatch[\"pmask\"], \n",
    "                                   xbatch[\"jmask\"]]), n_steps=50)\n",
    "print(\"ig done\")\n",
    "\n",
    "fa_attr_test = fa.attribute(tuple([xbatch[\"table\"], xbatch[\"pred\"],\n",
    "                            xbatch[\"join\"],\n",
    "                            xbatch[\"tmask\"], xbatch[\"pmask\"], \n",
    "                                   xbatch[\"jmask\"]]), n_steps=50)\n",
    "print(\"fa done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591c078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_attr_vecs(curx, curattrs):\n",
    "#     #idxs = 0\n",
    "#     xsum = curx.sum(axis=0).sum(axis=0)\n",
    "#     zero_idxs = xsum == 0\n",
    "#     curattrs = curattrs[:,:,~zero_idxs]\n",
    "#     idxs = np.array(range(len(xsum)))[~zero_idxs]\n",
    "#     curx = curx[:,:,~zero_idxs]\n",
    "    \n",
    "#     assert curx.shape == curattrs.shape\n",
    "    \n",
    "#     # TODO: avg based on non-zero elements\n",
    "#     attr_sum = curattrs.sum(axis=0).sum(axis=0)\n",
    "#     assert attr_sum.shape[0] == curx.shape[-1]\n",
    "    \n",
    "#     # TODO: do we need this?\n",
    "#     #attr_sum = attr_sum / np.linalg.norm(attr_sum, ord=1)\n",
    "    \n",
    "#     # TODO: do this or no?\n",
    "#     curx_nonz = curx != 0\n",
    "#     xnonzero_sums = curx_nonz.sum(axis=0).sum(axis=0)\n",
    "#     #xnonzero_sums += 1\n",
    "#     #print(xnonzero_sums)\n",
    "#     #print(xnonzero_sums)\n",
    "#     attr_sum = attr_sum / xnonzero_sums\n",
    "    \n",
    "#     return idxs, attr_sum\n",
    "\n",
    "# def get_mscn_attrs(xbatch, attrs, featurizer, normalize=True):\n",
    "#     '''\n",
    "#     returns a vector with x-axis names and attribution values;\n",
    "#     '''\n",
    "#     batchsize = xbatch[\"table\"].shape[0]\n",
    "#     assert batchsize == attrs[0].shape[0]\n",
    "#     tabidxs, tabattrs = get_attr_vecs(xbatch[\"table\"].detach().numpy(), attrs[0].detach().numpy())\n",
    "#     predidxs, predattrs = get_attr_vecs(xbatch[\"pred\"].detach().numpy(), attrs[1].detach().numpy())\n",
    "#     joinidxs, joinattrs = get_attr_vecs(xbatch[\"join\"].detach().numpy(), attrs[2].detach().numpy())\n",
    "    \n",
    "#     # TODO: need to do sample_bitmaps\n",
    "#     tablabels = []\n",
    "#     for curtabidx in tabidxs:\n",
    "#         for tab,tidx in featurizer.table_featurizer.items():\n",
    "#             if tidx == curtabidx:\n",
    "#                 tablabels.append(tab)\n",
    "#                 break\n",
    "#     joinlabels = []\n",
    "#     for curjidx in joinidxs:\n",
    "#         for join,jidx in featurizer.join_featurizer.items():\n",
    "#             found = False\n",
    "#             if curjidx == jidx:\n",
    "#                 joinlabels.append(join)\n",
    "#                 found = True\n",
    "#                 break\n",
    "#         if not found:\n",
    "#             joinlabels.append(\"unknown\")\n",
    "#     # TODO: join-stats\n",
    "    \n",
    "#     predlabels = []\n",
    "#     colstart,collen = featurizer.featurizer_type_idxs[\"col_onehot\"]\n",
    "#     # TODO: if stats used\n",
    "#     #colstatsstart,colstatsend = self.featurizer_type_idxs[\"col_stats\"]\n",
    "#     cmp_start,cmplen = featurizer.featurizer_type_idxs[\"cmp_op\"]\n",
    "#     cstart,clen = featurizer.featurizer_type_idxs[\"constant_continuous\"]\n",
    "#     lstart,llen = featurizer.featurizer_type_idxs[\"constant_like\"]\n",
    "#     dstart,dlen = featurizer.featurizer_type_idxs[\"constant_discrete\"]\n",
    "#     hstart,hlen = featurizer.featurizer_type_idxs[\"heuristic_ests\"]\n",
    "#     #print(hstart, hlen)\n",
    "#     for pi in predidxs:\n",
    "#         if pi >= colstart and pi < colstart+collen:\n",
    "#             found = False\n",
    "#             for col,colidx in featurizer.columns_onehot_idx.items():\n",
    "#                 if colidx == pi:\n",
    "#                     predlabels.append(col)\n",
    "#                     found = True\n",
    "#                     break\n",
    "#             if not found:\n",
    "#                 print(pi)\n",
    "#                 predlabels.append(\"col-unknown\")\n",
    "#         elif pi >= cmp_start and pi < cmp_start+cmplen:\n",
    "#             predlabels.append(\"cmp\")\n",
    "#         elif pi == cstart:\n",
    "#             predlabels.append(\"<\")\n",
    "#         elif pi == cstart+1:\n",
    "#             predlabels.append(\">\")\n",
    "#         elif pi >= lstart and pi < lstart+llen:\n",
    "#             predlabels.append(\"Like-Hash-\" + str(pi))\n",
    "#         elif pi >= dstart and pi < dstart+dlen:\n",
    "#             predlabels.append(\"Constant-Hash-\" + str(pi))\n",
    "#         elif pi == hstart:\n",
    "#             predlabels.append(\"PostgreSQL Est (Table)\")\n",
    "#         elif pi == hstart+1:\n",
    "#             predlabels.append(\"PostgreSQL Est (Subplan)\")\n",
    "    \n",
    "#     #assert len(predidxs) == len(predlabels)\n",
    "# #     print(len(predidxs), len(predlabels))\n",
    "# #     print(predidxs)\n",
    "# #     print(predlabels)\n",
    "#     attrs = np.concatenate([tabattrs, joinattrs, predattrs])\n",
    "#     xlabels = tablabels + joinlabels + predlabels\n",
    "    \n",
    "#     if normalize:\n",
    "#         attrs = attrs / np.linalg.norm(attrs, ord=1)\n",
    "    \n",
    "#     #xlabels = list(range(len(attrs)))\n",
    "#     return xlabels,attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2a6f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attr_vecs(curx, curattrs):\n",
    "    #idxs = 0\n",
    "    xsum = curx.sum(axis=0).sum(axis=0)\n",
    "    zero_idxs = xsum == 0\n",
    "    curattrs = curattrs[:,:,~zero_idxs]\n",
    "    idxs = np.array(range(len(xsum)))[~zero_idxs]\n",
    "    curx = curx[:,:,~zero_idxs]\n",
    "    \n",
    "    assert curx.shape == curattrs.shape\n",
    "    \n",
    "    # TODO: avg based on non-zero elements\n",
    "    \n",
    "    print(\"attr sum: \", np.sum(curattrs))\n",
    "    curattrs = np.abs(curattrs)\n",
    "    print(\"attr sum after abs: \", np.sum(curattrs))\n",
    "    \n",
    "    attr_sum = curattrs.sum(axis=0).sum(axis=0)\n",
    "    \n",
    "    assert attr_sum.shape[0] == curx.shape[-1]\n",
    "    \n",
    "    # TODO: do we need this?\n",
    "    #attr_sum = attr_sum / np.linalg.norm(attr_sum, ord=1)\n",
    "    \n",
    "    # TODO: do this or no?\n",
    "    curx_nonz = curx != 0\n",
    "    \n",
    "    xnonzero_sums = curx_nonz.sum(axis=0).sum(axis=0)\n",
    "    \n",
    "    #TODO?\n",
    "    attr_sum = attr_sum / xnonzero_sums\n",
    "    \n",
    "    return idxs, attr_sum\n",
    "\n",
    "def get_mscn_attrs(xbatch, attrs, featurizer, normalize=True):\n",
    "    '''\n",
    "    returns a vector with x-axis names and attribution values;\n",
    "    '''\n",
    "    batchsize = xbatch[\"table\"].shape[0]\n",
    "    assert batchsize == attrs[0].shape[0]\n",
    "    tabidxs, tabattrs = get_attr_vecs(xbatch[\"table\"].detach().numpy(), attrs[0].detach().numpy())\n",
    "    predidxs, predattrs = get_attr_vecs(xbatch[\"pred\"].detach().numpy(), attrs[1].detach().numpy())\n",
    "    joinidxs, joinattrs = get_attr_vecs(xbatch[\"join\"].detach().numpy(), attrs[2].detach().numpy())\n",
    "    \n",
    "    # TODO: need to do sample_bitmaps\n",
    "    tablabels = []\n",
    "    for curtabidx in tabidxs:\n",
    "        for tab,tidx in featurizer.table_featurizer.items():\n",
    "            if tidx == curtabidx:\n",
    "                tablabels.append(tab)\n",
    "                break\n",
    "    joinlabels = []\n",
    "    for curjidx in joinidxs:\n",
    "        for join,jidx in featurizer.join_featurizer.items():\n",
    "            found = False\n",
    "            if curjidx == jidx:\n",
    "                joinlabels.append(join)\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            joinlabels.append(\"unknown\")\n",
    "    # TODO: join-stats\n",
    "    \n",
    "    predlabels = []\n",
    "    colstart,collen = featurizer.featurizer_type_idxs[\"col_onehot\"]\n",
    "    # TODO: if stats used\n",
    "    #colstatsstart,colstatsend = self.featurizer_type_idxs[\"col_stats\"]\n",
    "    cmp_start,cmplen = featurizer.featurizer_type_idxs[\"cmp_op\"]\n",
    "    cstart,clen = featurizer.featurizer_type_idxs[\"constant_continuous\"]\n",
    "    lstart,llen = featurizer.featurizer_type_idxs[\"constant_like\"]\n",
    "    dstart,dlen = featurizer.featurizer_type_idxs[\"constant_discrete\"]\n",
    "    hstart,hlen = featurizer.featurizer_type_idxs[\"heuristic_ests\"]\n",
    "    #print(hstart, hlen)\n",
    "    for pi in predidxs:\n",
    "        if pi >= colstart and pi < colstart+collen:\n",
    "            found = False\n",
    "            for col,colidx in featurizer.columns_onehot_idx.items():\n",
    "                if colidx == pi:\n",
    "                    predlabels.append(col)\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                print(pi)\n",
    "                predlabels.append(\"col-unknown\")\n",
    "        elif pi >= cmp_start and pi < cmp_start+cmplen:\n",
    "            predlabels.append(\"cmp\")\n",
    "        elif pi == cstart:\n",
    "            predlabels.append(\"<\")\n",
    "        elif pi == cstart+1:\n",
    "            predlabels.append(\">\")\n",
    "        elif pi >= lstart and pi < lstart+llen:\n",
    "            predlabels.append(\"Like-Hash-\" + str(pi))\n",
    "        elif pi >= dstart and pi < dstart+dlen:\n",
    "            predlabels.append(\"Constant-Hash-\" + str(pi))\n",
    "        elif pi == hstart:\n",
    "            predlabels.append(\"PostgreSQL Est (Table)\")\n",
    "        elif pi == hstart+1:\n",
    "            predlabels.append(\"PostgreSQL Est (Subplan)\")\n",
    "    \n",
    "    #assert len(predidxs) == len(predlabels)\n",
    "#     print(len(predidxs), len(predlabels))\n",
    "#     print(predidxs)\n",
    "#     print(predlabels)\n",
    "    attrs = np.concatenate([tabattrs, joinattrs, predattrs])\n",
    "    xlabels = tablabels + joinlabels + predlabels\n",
    "    \n",
    "    if normalize:\n",
    "        attrs = attrs / np.linalg.norm(attrs, ord=1)\n",
    "    \n",
    "    return xlabels,attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97750b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabels, igattrs = get_mscn_attrs(xbatch, ig_attr_test, featurizer, normalize=True)\n",
    "xlabels, fattrs = get_mscn_attrs(xbatch, fa_attr_test, featurizer, normalize=True)\n",
    "print(xlabels)\n",
    "print(igattrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdccd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# plt.figure(figsize=(30, 10))\n",
    "# sns.barplot(x=xlabels, y=igattrs, color='#4260f5')\n",
    "\n",
    "plt.figure(figsize=(30, 20))\n",
    "plt.yticks(fontsize=20)\n",
    "sns.barplot(x=igattrs, y=xlabels, color='#4260f5', orient=\"horizontal\")\n",
    "plt.savefig(\"captum-mscn-dropout-2b.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d1b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(30, 10))\n",
    "sns.barplot(x=xlabels, y=fattrs, color='#4260f5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6346eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "curattrs = ig_attr_test[0].detach().numpy()\n",
    "print(curattrs.shape)\n",
    "curattrs.sum(axis=0).sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904e0bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer.featurizer_type_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c547b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xbatch[\"table\"].sum(axis=[0,1]))\n",
    "print(xbatch[\"pred\"].sum(axis=[0,1]))\n",
    "print(xbatch[\"join\"].sum(axis=[0,1]))\n",
    "\n",
    "print(xbatch[\"table\"].shape)\n",
    "print(xbatch[\"pred\"].shape)\n",
    "print(xbatch[\"join\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081895db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# print(torch.max(ig_attr_test[1]), torch.argmax(ig_attr_test[1]))\n",
    "# print(torch.max(fa_attr_test[1]), torch.argmax(fa_attr_test[1]))\n",
    "#len(ig_attr_test)\n",
    "\n",
    "# np.linalg.norm(ig_attr_test[1].detach().numpy(), ord=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481a1b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_attr_test[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcadbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(ig_attr_test[1][:,:,idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5066bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(ig_attr_test[1].shape[2]):\n",
    "    print(idx, torch.sum(ig_attr_test[1][:,:,idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bd50e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = init_featurizer(\"combined\")\n",
    "ds = QueryDataset(trainqs, featurizer,\n",
    "        False,\n",
    "        load_padded_mscn_feats=False)\n",
    "\n",
    "# featurizer = init_featurizer(\"set\")\n",
    "# ds = QueryDataset(trainqs, featurizer,\n",
    "#         False,\n",
    "#         load_padded_mscn_feats=True)\n",
    "model = fcnn.net\n",
    "\n",
    "ig = IntegratedGradients(model)\n",
    "ig_nt = NoiseTunnel(ig)\n",
    "dl = DeepLift(model)\n",
    "gs = GradientShap(model)\n",
    "fa = FeatureAblation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e5a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = ds.X[32:35]\n",
    "X_train = ds.X[32:35]\n",
    "\n",
    "ig_attr_test = ig.attribute(X_test, n_steps=50)\n",
    "print(\"ig done\")\n",
    "ig_nt_attr_test = ig_nt.attribute(X_test)\n",
    "dl_attr_test = dl.attribute(X_test)\n",
    "print(\"dl done\")\n",
    "gs_attr_test = gs.attribute(X_test, X_train)\n",
    "print(\"gs done\")\n",
    "fa_attr_test = fa.attribute(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e92ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_attr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7d2609",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5107ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets find all the zeros in X_test\n",
    "combined_vec = X_test.sum(axis=0)\n",
    "zero_idxs = combined_vec == 0\n",
    "X_test_nonzero = X_test[:,~zero_idxs]\n",
    "ig_attr_test = ig_attr_test[:,~zero_idxs]\n",
    "ig_nt_attr_test = ig_nt_attr_test[:,~zero_idxs]\n",
    "dl_attr_test = dl_attr_test[:,~zero_idxs]\n",
    "gs_attr_test = gs_attr_test[:,~zero_idxs]\n",
    "fa_attr_test = fa_attr_test[:,~zero_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a97acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fcnn.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d2da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis_data = np.arange(X_test_nonzero.shape[1])\n",
    "x_axis_data_labels = list(map(lambda idx: idx, x_axis_data))\n",
    "\n",
    "ig_attr_test_sum = ig_attr_test.detach().numpy().sum(0)\n",
    "ig_attr_test_norm_sum = ig_attr_test_sum / np.linalg.norm(ig_attr_test_sum, ord=1)\n",
    "\n",
    "ig_nt_attr_test_sum = ig_nt_attr_test.detach().numpy().sum(0)\n",
    "ig_nt_attr_test_norm_sum = ig_nt_attr_test_sum / np.linalg.norm(ig_nt_attr_test_sum, ord=1)\n",
    "\n",
    "dl_attr_test_sum = dl_attr_test.detach().numpy().sum(0)\n",
    "dl_attr_test_norm_sum = dl_attr_test_sum / np.linalg.norm(dl_attr_test_sum, ord=1)\n",
    "\n",
    "gs_attr_test_sum = gs_attr_test.detach().numpy().sum(0)\n",
    "gs_attr_test_norm_sum = gs_attr_test_sum / np.linalg.norm(gs_attr_test_sum, ord=1)\n",
    "\n",
    "fa_attr_test_sum = fa_attr_test.detach().numpy().sum(0)\n",
    "fa_attr_test_norm_sum = fa_attr_test_sum / np.linalg.norm(fa_attr_test_sum, ord=1)\n",
    "\n",
    "lin_weight = model.layers[0][0].weight.detach().numpy()\n",
    "y_axis_lin_weight = lin_weight / np.linalg.norm(lin_weight, ord=1)\n",
    "\n",
    "width = 0.14\n",
    "legends = ['Int Grads', 'Int Grads w/SmoothGrad','DeepLift', 'GradientSHAP', 'Feature Ablation', 'Weights']\n",
    "\n",
    "plt.figure(figsize=(30, 10))\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.set_title('Comparing input feature importances across multiple algorithms and learned weights')\n",
    "ax.set_ylabel('Attributions')\n",
    "\n",
    "FONT_SIZE = 16\n",
    "plt.rc('font', size=FONT_SIZE)            # fontsize of the text sizes\n",
    "plt.rc('axes', titlesize=FONT_SIZE)       # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=FONT_SIZE)       # fontsize of the x and y labels\n",
    "plt.rc('legend', fontsize=FONT_SIZE - 4)  # fontsize of the legend\n",
    "\n",
    "ax.bar(x_axis_data, ig_attr_test_norm_sum, width, align='center', alpha=0.8, color='#eb5e7c')\n",
    "ax.bar(x_axis_data + width, ig_nt_attr_test_norm_sum, width, align='center', alpha=0.7, color='#A90000')\n",
    "ax.bar(x_axis_data + 2 * width, dl_attr_test_norm_sum, width, align='center', alpha=0.6, color='#34b8e0')\n",
    "ax.bar(x_axis_data + 3 * width, gs_attr_test_norm_sum, width, align='center',  alpha=0.8, color='#4260f5')\n",
    "ax.bar(x_axis_data + 4 * width, fa_attr_test_norm_sum, width, align='center', alpha=1.0, color='#49ba81')\n",
    "\n",
    "#ax.bar(x_axis_data + 5 * width, y_axis_lin_weight, width, align='center', alpha=1.0, color='grey')\n",
    "ax.autoscale_view()\n",
    "plt.tight_layout()\n",
    "\n",
    "ax.set_xticks(x_axis_data + 0.5)\n",
    "ax.set_xticklabels(x_axis_data_labels)\n",
    "\n",
    "plt.legend(legends, loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7443c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(dl_attr_test_sum, ord=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe1c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_attr_test_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6309fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_attr_test.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7971e8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
